#!/usr/bin/env python3
"""
Interface web Flask pour la classification de chiffres MNIST avec PyTorch
"""

import os
import io
import base64
import numpy as np
from PIL import Image
from flask import Flask, render_template, request, jsonify, flash, redirect, url_for
from flask_cors import CORS
import cv2
import torch

from src.model import MNISTModel
from src.data_loader import MNISTDataLoader

app = Flask(__name__, template_folder='docs')
app.secret_key = 'mnist_classification_secret_key'
CORS(app)

# Configuration
MODEL_PATH = 'models/mnist_model.pth'

# Cr√©er les dossiers n√©cessaires
os.makedirs('docs', exist_ok=True)

# Charger le mod√®le globalement
model = None
device = None

def get_device():
    """D√©termine le meilleur device disponible"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    elif torch.backends.mps.is_available():
        return torch.device('mps')
    else:
        return torch.device('cpu')

def load_model():
    """Charge le mod√®le MNIST PyTorch"""
    global model, device
    if model is None:
        if os.path.exists(MODEL_PATH):
            device = get_device()
            model = MNISTModel(device=device)
            model.load_model(MODEL_PATH)
            print(f"‚úÖ Mod√®le PyTorch charg√© depuis {MODEL_PATH}")
            print(f"üéØ Device utilis√©: {device}")
        else:
            print(f"‚ùå Mod√®le non trouv√© dans {MODEL_PATH}")
            print("Veuillez d'abord entra√Æner le mod√®le avec: python train.py")
    return model



def process_canvas_image(image_data):
    """Traite une image dessin√©e sur le canvas avec PyTorch"""
    try:
        print(f"üîç DEBUG Canvas - D√©but du traitement")
        print(f"üîç Donn√©es re√ßues: {len(image_data)} caract√®res, d√©but: {image_data[:50]}...")
        
        # D√©coder l'image base64
        header, encoded = image_data.split(',', 1)
        image_bytes = base64.b64decode(encoded)
        image = Image.open(io.BytesIO(image_bytes))
        
        print(f"üîç Image d√©cod√©e: taille={image.size}, mode={image.mode}")
        
        # Convertir en niveaux de gris avec gestion de la transparence
        if image.mode == 'RGBA':
            # Cr√©er un fond blanc et composer l'image dessus
            background = Image.new('RGB', image.size, (255, 255, 255))
            background.paste(image, mask=image.split()[-1])  # Utiliser le canal alpha comme masque
            image = background.convert('L')
            print(f"üîç Conversion RGBA‚ÜíL avec fond blanc")
        elif image.mode != 'L':
            image = image.convert('L')
        
        # Convertir en array numpy
        img_array = np.array(image)
        print(f"üîç Array original: shape={img_array.shape}, min/max={img_array.min()}/{img_array.max()}")
        
        # Redimensionner √† 28x28
        img_resized = cv2.resize(img_array, (28, 28))
        print(f"üîç Apr√®s resize: shape={img_resized.shape}, min/max={img_resized.min()}/{img_resized.max()}")
        
        # Inverser les couleurs (canvas noir sur blanc -> blanc sur noir)
        img_resized = 255 - img_resized
        print(f"üîç Apr√®s inversion: min/max={img_resized.min()}/{img_resized.max()}")
        
        # Normaliser (0-255 -> 0-1)
        img_normalized = img_resized.astype('float32') / 255.0
        print(f"üîç Apr√®s norm 0-1: min/max={img_normalized.min():.3f}/{img_normalized.max():.3f}")
        
        # Appliquer la m√™me normalisation que pour l'entra√Ænement
        img_normalized = (img_normalized - 0.1307) / 0.3081
        print(f"üîç Apr√®s norm MNIST: min/max={img_normalized.min():.3f}/{img_normalized.max():.3f}")
        
        # V√©rifier les valeurs uniques
        unique_vals = np.unique(img_normalized)
        print(f"üîç Valeurs uniques: {len(unique_vals)} (√©chantillon: {unique_vals[:5]})")
        
        # Convertir en tensor PyTorch
        img_tensor = torch.FloatTensor(img_normalized).unsqueeze(0).unsqueeze(0)
        print(f"üîç Tensor final: shape={img_tensor.shape}")
        
        return img_tensor, img_resized
    
    except Exception as e:
        print(f"‚ùå Erreur lors du traitement canvas: {e}")
        import traceback
        traceback.print_exc()
        return None, None

@app.route('/')
def index():
    """Page d'accueil"""
    return render_template('index.html')



@app.route('/predict_canvas', methods=['POST'])
def predict_canvas():
    """Pr√©diction √† partir du dessin sur canvas"""
    try:
        data = request.get_json()
        if 'image' not in data:
            return jsonify({'error': 'Donn√©es d\'image manquantes'}), 400
        
        # Charger le mod√®le
        model = load_model()
        if model is None:
            return jsonify({'error': 'Mod√®le non disponible. Veuillez d\'abord entra√Æner le mod√®le avec: python train.py'}), 500
        
        # Traiter l'image du canvas
        processed_img, display_img = process_canvas_image(data['image'])
        if processed_img is None:
            return jsonify({'error': 'Erreur lors du traitement de l\'image du canvas'}), 400
        
        # Faire la pr√©diction
        print(f"üîç DEBUG - Avant pr√©diction, input shape: {processed_img.shape}")
        prediction, confidence = model.predict(processed_img)
        print(f"üîç DEBUG - Apr√®s pr√©diction: {prediction} (confiance: {confidence:.3f})")
        
        response_data = {
            'prediction': int(prediction),
            'confidence': float(confidence),
            'message': f'Le chiffre pr√©dit est {prediction} avec une confiance de {confidence*100:.1f}%'
        }
        
        print(f"üé® Canvas - Pr√©diction: {prediction}, Confiance: {confidence:.3f}")
        return jsonify(response_data)
    
    except Exception as e:
        print(f"Erreur dans predict_canvas: {str(e)}")
        return jsonify({'error': f'Erreur interne du serveur: {str(e)}'}), 500

@app.route('/model_info')
def model_info():
    """Informations sur le mod√®le PyTorch"""
    try:
        model = load_model()
        if model is None:
            return jsonify({'error': 'Mod√®le non disponible'}), 500
        
        # Compter les param√®tres
        total_params = sum(p.numel() for p in model.model.parameters())
        trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)
        
        info = {
            'model_loaded': True,
            'model_path': MODEL_PATH,
            'framework': 'PyTorch',
            'device': str(device),
            'input_shape': [1, 28, 28],
            'output_classes': 10,
            'class_names': [str(i) for i in range(10)],
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'model_size_mb': round(total_params * 4 / (1024 * 1024), 2),  # Estimation en float32
            'architecture': {
                'type': 'Convolutional Neural Network (CNN)',
                'layers': [
                    'Conv2d(1, 32, kernel_size=3, padding=1)',
                    'MaxPool2d(2, 2)',
                    'Conv2d(32, 64, kernel_size=3, padding=1)', 
                    'MaxPool2d(2, 2)',
                    'Conv2d(64, 64, kernel_size=3, padding=1)',
                    'Linear(3136, 64)',
                    'Dropout(0.5)',
                    'Linear(64, 10)'
                ]
            }
        }
        
        return jsonify(info)
    
    except Exception as e:
        return jsonify({'error': f'Erreur: {str(e)}'}), 500

@app.route('/health')
def health():
    """Endpoint de sant√©"""
    global model, device
    
    health_info = {
        'status': 'healthy',
        'model_available': model is not None,
        'framework': 'PyTorch',
        'pytorch_version': torch.__version__
    }
    
    if device:
        health_info['device'] = str(device)
        
    if torch.cuda.is_available():
        health_info['cuda_available'] = True
        health_info['cuda_device_count'] = torch.cuda.device_count()
        if torch.cuda.current_device() >= 0:
            health_info['cuda_current_device'] = torch.cuda.get_device_name()
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        health_info['mps_available'] = True
    
    return jsonify(health_info)

@app.route('/test_prediction')
def test_prediction():
    """Endpoint de test pour v√©rifier que le mod√®le fonctionne"""
    try:
        model = load_model()
        if model is None:
            return jsonify({'error': 'Mod√®le non disponible'}), 500
        
        # Cr√©er une image de test simple (chiffre 0)
        test_image = np.zeros((28, 28), dtype=np.float32)
        
        # Dessiner un cercle simple pour ressembler √† un 0
        center = (14, 14)
        radius = 8
        y, x = np.ogrid[:28, :28]
        mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
        outer_mask = (x - center[0])**2 + (y - center[1])**2 <= (radius-2)**2
        test_image[mask & ~outer_mask] = 1.0
        
        # Normaliser comme dans l'entra√Ænement
        test_image = (test_image - 0.1307) / 0.3081
        
        # Convertir en tensor PyTorch
        test_tensor = torch.FloatTensor(test_image).unsqueeze(0).unsqueeze(0)
        
        # Pr√©diction
        prediction, confidence = model.predict(test_tensor)
        
        return jsonify({
            'test_successful': True,
            'prediction': int(prediction),
            'confidence': float(confidence),
            'message': f'Test r√©ussi! Pr√©diction: {prediction}, Confiance: {confidence:.3f}'
        })
    
    except Exception as e:
        return jsonify({
            'test_successful': False,
            'error': str(e)
        }), 500

@app.errorhandler(413)
def too_large(e):
    """Gestionnaire d'erreur pour les fichiers trop volumineux"""
    return jsonify({'error': 'Fichier trop volumineux. Taille maximale: 16MB'}), 413

@app.errorhandler(500)
def internal_error(e):
    """Gestionnaire d'erreur interne"""
    return jsonify({'error': 'Erreur interne du serveur'}), 500

if __name__ == '__main__':
    print("=== üî• Interface Web MNIST avec PyTorch ===")
    print("Initialisation...")
    
    # D√©tection du device
    device = get_device()
    print(f"üéØ Device d√©tect√©: {device}")
    
    # Information sur PyTorch
    print(f"üî• Version PyTorch: {torch.__version__}")
    
    if torch.cuda.is_available():
        print(f"‚ö° CUDA disponible: {torch.cuda.device_count()} device(s)")
        print(f"   GPU actuel: {torch.cuda.get_device_name()}")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("üçé Apple Silicon MPS disponible")
    
    print("\nChargement du mod√®le...")
    load_model()
    
    if model is not None:
        print("‚úÖ Mod√®le charg√© avec succ√®s!")
        print("üåê D√©marrage du serveur web...")
        print("üìç Acc√©dez √† l'application: http://localhost:5001")
        print("\nüéØ Endpoints disponibles:")
        print("   - GET  /              : Interface principale")
        print("   - POST /predict_canvas: Pr√©diction par dessin")
        print("   - GET  /model_info    : Informations du mod√®le")
        print("   - GET  /health        : √âtat du syst√®me")
        print("   - GET  /test_prediction: Test du mod√®le")
    else:
        print("‚ö†Ô∏è  Mod√®le non trouv√©, mais le serveur d√©marre quand m√™me.")
        print("   Entra√Ænez d'abord le mod√®le avec: python train.py")
        print("üåê Serveur disponible sur: http://localhost:5001")
        print("   (La fonctionnalit√© de pr√©diction sera d√©sactiv√©e)")
    
    print("\n" + "="*50)
    
    app.run(debug=True, host='0.0.0.0', port=5001) 